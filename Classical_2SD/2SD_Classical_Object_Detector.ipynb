{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move test documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 13347.65it/s]\n"
     ]
    }
   ],
   "source": [
    "db_path = \"../../Datasets/Objects_Database/\"\n",
    "tb_path = \"../../Datasets/Tobacco 800 Dataset/tobacco800\"\n",
    "dst_path = os.path.join(db_path, \"test_documents\")\n",
    "\n",
    "\n",
    "object_info_file = os.path.join(db_path, \"2_Selected_Objects_Information.csv\")\n",
    "objects_info_df = pd.read_csv(object_info_file)\n",
    "\n",
    "u_test_docs = objects_info_df.loc[objects_info_df[\"set\"]==\"test\", \"image_name\"].unique()\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(u_test_docs))):\n",
    "    image_name = u_test_docs[i]\n",
    "    src_file = os.path.join(tb_path, image_name+\".png\")\n",
    "    dst_file = os.path.join(dst_path, image_name+\".png\")\n",
    "\n",
    "    shutil.copy2(src=src_file, dst=dst_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Stage object detector Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "u_test_docs = objects_info_df.loc[objects_info_df[\"set\"]==\"test\", \"image_name\"].unique()\n",
    "print(u_test_docs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn import svm\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(img, cmap=\"gray\", title=\"img\", fontsize=12):\n",
    "\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # plt.figure()\n",
    "    plt.imshow(image)#, cmap=cmap)\n",
    "    plt.title(title)#, fontsize=fontsize)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # plt.show()\n",
    "\n",
    "def create_dir(path):\n",
    "\n",
    "    dirs = path.split(\"/\")\n",
    "    n_path = \"\"\n",
    "    for i in range(len(dirs)):\n",
    "        \n",
    "        n_path = os.path.join(n_path, dirs[i])\n",
    "        # print(n_path)\n",
    "        a = os.path.isdir(n_path)   \n",
    "        # print(a) \n",
    "        if(not(a)):\n",
    "            os.mkdir(n_path)      \n",
    "\n",
    "\n",
    "def check_area(obj_contours, n_std=0):\n",
    "    ## List to save the area of objects ##\n",
    "    area_arr = np.empty(0)\n",
    "    ## Loop ##\n",
    "    for cnt in (obj_contours):\n",
    "        ## calcular area del objeto ##\n",
    "        area = cv2.contourArea(cnt)\n",
    "        ## Save value ##\n",
    "        area_arr = np.append(area_arr, area)\n",
    "    \n",
    "    \n",
    "    ## return area threshold to select objects ##\n",
    "    area_mean = np.mean(area_arr)\n",
    "    area_std = np.std(area_arr)\n",
    "    \n",
    "    area_th = area_mean + n_std*area_std\n",
    "    \n",
    "    # print(a_mean)\n",
    "    return area_th\n",
    "\n",
    "\n",
    "def object_segmentation_prediction(doc_file, classifier, normalize_transfor, save_path=\"\", kp=16, n_std=1, margin=0, lw=4):\n",
    "    \n",
    "    ##########################################\n",
    "    ############## Load data #################\n",
    "    ##########################################\n",
    "    ## Split doc name ##\n",
    "    doc_name = doc_file.split(\"/\")[-1].split(\".\")[0]\n",
    "  \n",
    "    #### Invert images ####\n",
    "    inv = False\n",
    "    \n",
    "    ## Load image ##\n",
    "    image = cv2.imread(doc_file)\n",
    "    \n",
    "    ## Copy original image ##\n",
    "    img = image.copy()\n",
    "    ## image to draw contours ##\n",
    "    img_contour = image.copy()\n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    ############## Image processing #################\n",
    "    #################################################\n",
    "    \n",
    "    #### Image preprocessing ####\n",
    "    ## image to gray scale ##\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ## Compute kernel size ##\n",
    "    k = min(img.shape)//kp\n",
    "    if((k%2)==0):\n",
    "        k -= 1\n",
    "    # print(f\"imagesize: {img.shape}, kernel size: ({k},{k})\")\n",
    "    \n",
    "    ## Filtering ##\n",
    "    sigmax = 0\n",
    "    kernel = (k,k)\n",
    "    img = cv2.GaussianBlur(img, kernel, sigmax)\n",
    "    # gk = cv2.getGaussianKernel(k, sigmax)\n",
    "    # print_image(image, title=\"gaussian\")\n",
    "\n",
    "    #### binarization by otzu ####\n",
    "    if(inv):\n",
    "        u, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        u, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # print_image(img)\n",
    "\n",
    "    #################################################\n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Object serach #################\n",
    "    ##############################################\n",
    "    \n",
    "    #### search contours ####\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    #print(\"Contours:\",len(contours))\n",
    "\n",
    "    #### lista para almacenar los objetos ####\n",
    "    objects_list = []\n",
    "    areas_list = []\n",
    "    annotations_list = []\n",
    "    \n",
    "    #### Check object area ####\n",
    "    # n_std: Number of standar deviation values ober the mean to define the threshold.\n",
    "    area_threshold = check_area(contours, n_std)\n",
    "\n",
    "    ### HOG Parameters ####\n",
    "    dim = (512, 256)\n",
    "    orientations = 9\n",
    "    pixels_per_cell = 64\n",
    "    cells_per_block = 2\n",
    "    block_norm = \"L2-Hys\"\n",
    "    \n",
    "    \n",
    "    for i in range(len(contours)):\n",
    "        \n",
    "        cnt = contours[i]\n",
    "        \n",
    "        #### calcular area del objeto ####\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        if(area > area_threshold):\n",
    "        \n",
    "            #### calcular el rctangulo que enciarra al objeto ####\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            ## Save annotations ##\n",
    "            annotations_list.append([x, y, w, h])\n",
    "            \n",
    "            ## Segmentar el objeto deseado ##\n",
    "            img_object = image[y-margin : y+h+margin, x-margin : x+w+margin, :]\n",
    "            \n",
    "            ## image to gray scale ##\n",
    "            img_object = cv2.cvtColor(img_object, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #### Reshape image #### \n",
    "            img_object = cv2.resize(img_object, dim, interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            ################################\n",
    "            #### HOG feature extraction ####\n",
    "            ################################ \n",
    "            hog_vec = hog(img_object, orientations=orientations, pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "                                    cells_per_block=(cells_per_block, cells_per_block), block_norm=block_norm, visualize=False)\n",
    "            \n",
    "            X = np.asarray(hog_vec)\n",
    "            X = X.reshape(1, len(X))\n",
    "            col_name = [f\"hog_{i}\" for i in range(X.shape[1])]\n",
    "            X = pd.DataFrame(X, columns=col_name)\n",
    "            \n",
    "    \n",
    "            #########################\n",
    "            #### Standarize data ####\n",
    "            #########################\n",
    "            X = normalize_transfor.transform(X)\n",
    "            \n",
    "            #########################\n",
    "            #### Data prediction ####\n",
    "            #########################\n",
    "            ## Predictions ##\n",
    "            y_pred = classifier.predict(X)[0]\n",
    "            \n",
    "\n",
    "            label_map = {\n",
    "                0:\"logo\",\n",
    "                1:\"signature\",\n",
    "                2:\"other\",\n",
    "            }\n",
    "            \n",
    "\n",
    "            if(y_pred==2):\n",
    "                continue\n",
    "\n",
    "            label_name = label_map[y_pred]\n",
    "     \n",
    "            #### dibujar el rectangulo que encierra al objeto ####\n",
    "            cv2.rectangle(img_contour, (x,y), (x+w, y+h), (0,255,0), lw)\n",
    "                            \n",
    "            ## Select cordinates for the label ##\n",
    "            x_pos = x+w//4\n",
    "            y_pos = y+h//2\n",
    "            \n",
    "            ## Add the label text to the image ##\n",
    "            img_contour = cv2.putText(img_contour, label_name, org=(x_pos, y_pos), fontFace=cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                    fontScale=3, color=(0, 0, 255), thickness=10) \n",
    "    \n",
    "\n",
    "            ## Check for directory ##\n",
    "            if(save_path != \"\"):\n",
    "                create_dir(os.path.join(save_path, label_name))\n",
    "                save_file = os.path.join(save_path, label_name, doc_name+f\"_{label_name}_{i}.png\")\n",
    "                cv2.imwrite(save_file, img_object)\n",
    "            \n",
    "            #### almacenar caracteres en una lista ####\n",
    "            objects_list.append(img_object)\n",
    "            areas_list.append(area)\n",
    "            #print(caracter_2.shape)\n",
    "\n",
    "\n",
    "    #### imprimir imagen con los contornos dibujados ####\n",
    "    # print_image(imgContour, save=False)\n",
    "    # cv2.imwrite(doc_name+\"_objects.png\", img_contour)\n",
    "    \n",
    "    # print(f\"caracteres encontrados: {len(objects_list)}\")\n",
    "    # print(f\"Area minima: {min(areas_list)}, Area maxima: {max(areas_list)}, Area mean: {np.mean(areas_list)}.\")\n",
    "    \n",
    "    #### retornar lista de los caracteres encontrados ####        \n",
    "    # return img_contour, objects_list\n",
    "    return img_contour, objects_list, areas_list, annotations_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:06<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "#### documents path ####\n",
    "## Images path ##\n",
    "# doc_path = \"../../Datasets/Objects_Database/Example_Documents\"\n",
    "doc_path = \"../../Datasets/Objects_Database/test_documents\"\n",
    "\n",
    "dst_path = \"../../Data/Classical_Object_Detection_Evaluation/\"\n",
    "\n",
    "create_dir(dst_path)\n",
    "\n",
    "## Kernel proportions size ##\n",
    "kp_list = [40]\n",
    "## Std over mean as threshold ##\n",
    "n_std = 0\n",
    "\n",
    "selected_documents = os.listdir(doc_path)\n",
    "print(f\"Number of documents:{len(selected_documents)}\")\n",
    "\n",
    "#### Model information ####\n",
    "model_path = \"../../Datasets/Objects_Database/Classical_Model\"\n",
    "standarization_file = os.path.join(model_path, \"std_selected_train_data_204(other_signature_logo).joblib\")\n",
    "model_file = os.path.join(model_path, \"Model(SVM)_K(rbf)_C(100)_G(0.001)_HOG_Feat(756)_img(256, 512)_O(9)_C(64)_B(2)_N(L2-Hys).joblib\")\n",
    "\n",
    "## Load stadarizer ##\n",
    "normalize_transfor = load(standarization_file)\n",
    "## Load model ##\n",
    "classifier = load(model_file)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "\n",
    "for kp in kp_list:\n",
    "    \n",
    "    ## Path to save results ##\n",
    "    save_path = \"\"\n",
    "\n",
    "    for i in tqdm(range(len(selected_documents))):\n",
    "        \n",
    "        doc_name = selected_documents[i]\n",
    "        doc_file = os.path.join(doc_path, doc_name)\n",
    "        \n",
    "        # print(doc_name)\n",
    "        # print(doc_file)\n",
    "        ## Searching ##\n",
    "        img_contour, objects_list, areas_list, annotations_list = object_segmentation_prediction(doc_file, classifier, normalize_transfor, save_path, \n",
    "                                                                                                kp, n_std, margin=0, lw=4)\n",
    "        \n",
    "        \n",
    "        dst_file = os.path.join(dst_path, doc_name)\n",
    "        cv2.imwrite(dst_file, img_contour)\n",
    "        \n",
    "        ## Make graphic ##\n",
    "        # plt.subplot(1, len(selected_documents), i+1)\n",
    "        # print_image(img_contour, title=\"Object proposal and classification\")\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
