{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select unlabeled documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1292\n",
      "792\n"
     ]
    }
   ],
   "source": [
    "db_path = \"../../Datasets/Tobacco 800 Dataset/tobacco800\"\n",
    "annotated_images = \"../../Old_Data/Annotated_Images\"\n",
    "ann_img_list = os.listdir(annotated_images)\n",
    "images_list = os.listdir(db_path)\n",
    "print(len(ann_img_list))\n",
    "print(len(images_list))\n",
    "\n",
    "## Remove annotated images ##\n",
    "for img_f in ann_img_list:\n",
    "    file = img_f+\".png\"\n",
    "    images_list.remove(file)\n",
    "\n",
    "print(len(images_list))\n",
    "\n",
    "\n",
    "src_path = db_path\n",
    "dst_path = \"../../Data/Images_2_Annotate/\"\n",
    "\n",
    "for file in images_list:\n",
    "    src_file = os.path.join(src_path, file)\n",
    "    dst_file = os.path.join(dst_path, file)\n",
    "    shutil.copy2(src_file, dst_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ground truth anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_yolo_annotations(annotation_file):\n",
    "    \"\"\"\n",
    "    Load YOLOv5 annotations from a file.\n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            _, _, _, width, height = map(float, line.strip().split())\n",
    "            bboxes.append((width, height))\n",
    "    return bboxes\n",
    "\n",
    "def get_ground_truth_bboxes(dataset_path):\n",
    "    \"\"\"\n",
    "    Extract ground truth bounding box widths and heights from a YOLOv5 formatted dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset_path: Path to the dataset directory containing the 'train' folder with images and annotations.\n",
    "    \n",
    "    Returns:\n",
    "    - bboxes: List of tuples containing the width and height of each bounding box.\n",
    "    \"\"\"\n",
    "    train_path = os.path.join(dataset_path, 'train')\n",
    "    annotations_path = os.path.join(train_path, 'labels')\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    for annotation_file in os.listdir(annotations_path):\n",
    "        if annotation_file.endswith('.txt'):\n",
    "            annotation_file_path = os.path.join(annotations_path, annotation_file)\n",
    "            bboxes += load_yolo_annotations(annotation_file_path)\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "# Example usage\n",
    "dataset_path = 'path/to/your/yolov5/dataset'\n",
    "bboxes = get_ground_truth_bboxes(dataset_path)\n",
    "\n",
    "# Print the first 10 bounding boxes\n",
    "for bbox in bboxes[:10]:\n",
    "    print(f\"Width: {bbox[0]}, Height: {bbox[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors for (640x640): [(72.0, 89.0), (400.0, 500.0), (226.67, 273.33)]\n",
      "Anchors for P3/8: [(9.0, 11.12), (50.0, 62.5), (28.33, 34.17)]\n",
      "Anchors for P4/16: [(4.5, 5.56), (25.0, 31.25), (14.17, 17.08)]\n",
      "Anchors for P5/32: [(2.25, 2.78), (12.5, 15.62), (7.08, 8.54)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_anchors(bboxes, num_anchors):\n",
    "    kmeans = KMeans(n_clusters=num_anchors, random_state=0).fit(bboxes)\n",
    "    anchors = kmeans.cluster_centers_\n",
    "    return anchors\n",
    "\n",
    "# Example ground truth bounding boxes (width, height)\n",
    "bboxes = np.array([\n",
    "    [30, 40],\n",
    "    [50, 80],\n",
    "    [100, 120],\n",
    "    [200, 300],\n",
    "    [60, 45],\n",
    "    [120, 160],\n",
    "    [160, 200],\n",
    "    [320, 320],\n",
    "    [400, 500],\n",
    "    # Add more bounding boxes from your dataset\n",
    "])\n",
    "\n",
    "# Perform k-means clustering to find the anchor boxes\n",
    "num_anchors = 3  # Total number of anchors\n",
    "anchors = kmeans_anchors(bboxes, num_anchors)\n",
    "\n",
    "# Define the scaling factors for each stage\n",
    "scale_factor_p3 = 8\n",
    "scale_factor_p4 = 16\n",
    "scale_factor_p5 = 32\n",
    "\n",
    "# Scale all anchors according to each feature map size\n",
    "anchors_in = [(round(w,2) , round(h,2) ) for w, h in anchors]\n",
    "anchors_p3 = [(round(w / scale_factor_p3, 2), round(h / scale_factor_p3, 2)) for w, h in anchors]\n",
    "anchors_p4 = [(round(w / scale_factor_p4, 2), round(h / scale_factor_p4, 2)) for w, h in anchors]\n",
    "anchors_p5 = [(round(w / scale_factor_p5, 2), round(h / scale_factor_p5, 2)) for w, h in anchors]\n",
    "# Print the scaled anchors\n",
    "print(\"Anchors for (640x640):\", anchors_in)\n",
    "print(\"Anchors for P3/8:\", anchors_p3)\n",
    "print(\"Anchors for P4/16:\", anchors_p4)\n",
    "print(\"Anchors for P5/32:\", anchors_p5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
